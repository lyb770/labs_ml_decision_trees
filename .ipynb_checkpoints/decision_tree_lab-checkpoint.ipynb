{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting course evaluations with Decision Trees\n",
    "\n",
    "\n",
    "## 1. CART Algorithm Implementation\n",
    "\n",
    "### 1.1. Tree data structure and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col = col # attribute on which to split\n",
    "        self.value = value # value on which to split\n",
    "        self.results = results # If the node has no children - we store here class labels with their counts\n",
    "        self.tb = tb  # True branch\n",
    "        self.fb = fb  # False branch\n",
    "        \n",
    "def split(rows, column, value):\n",
    "    # define split function according to the value type\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        split_function = lambda row: row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row: row[column] == value\n",
    "\n",
    "    # Divide the rows into two sets and return them\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return (set1, set2)\n",
    "\n",
    "def count_labels(rows):\n",
    "    label_count = {}\n",
    "    for row in rows:\n",
    "        # The class label is in the last column\n",
    "        label = row[- 1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Node purity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def gini_impurity(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    gini = 0\n",
    "    for key, val in counts.items():\n",
    "        p = val / total\n",
    "        gini += p*p\n",
    "        \n",
    "    return (1 - gini)\n",
    "\n",
    "def entropy(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    ent = 0.0\n",
    "    for key,val in counts.items():\n",
    "        p = val / total\n",
    "        ent = ent - p * log(p, 2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def variance(rows):\n",
    "    if len(rows) == 0: return 0\n",
    "    num_label = [float(row[- 1]) for row in rows]\n",
    "    mean = sum(num_label) / len(num_label)\n",
    "    variance = sum([(d - mean) ** 2 for d in num_label]) / len(num_label)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tree induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(rows, score_func=entropy, min_improvement=0, min_samples=0, max_depth=None, depth=0):\n",
    "    if len(rows) == 0:\n",
    "        return DecisionNode()\n",
    "    # Compute overall score for the entire rows dataset\n",
    "    current_score = score_func(rows)\n",
    "\n",
    "    # Set up accumulator variables to track the best split criteria\n",
    "    best_score = current_score\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    \n",
    "    # Total number of features - except the last column where we store the class (target)\n",
    "    column_count = len(rows[0]) - 1 \n",
    "    for col in range(0, column_count):\n",
    "        # Generate the list of unique values in\n",
    "        # this column to split on them\n",
    "        column_values = set()\n",
    "        for row in rows:\n",
    "            column_values.add(row[col])\n",
    "            \n",
    "        # Now try splitting the rows \n",
    "        # on each unique value in this column\n",
    "        for value in column_values:\n",
    "            (set1, set2) = split(rows, col, value)\n",
    "\n",
    "            # Evaluate the quality of the split\n",
    "            # p is the proportion of subset set1 \n",
    "            p = float(len(set1)) / len(rows)\n",
    "            split_score = p * score_func(set1) + (1-p) * score_func(set2)\n",
    "            \n",
    "            if split_score < best_score and \\\n",
    "                (len(set1) > min_samples and len(set2) > min_samples) and \\\n",
    "                (current_score - split_score) > min_improvement:\n",
    "                best_score = split_score\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1, set2)\n",
    "\n",
    "    # Create the sub branches\n",
    "    if (current_score - best_score) > min_improvement and \\\n",
    "        (max_depth is None or depth < max_depth) :\n",
    "        # print(\"Splitting on\",best_criteria, \" 2 sets:\", len(best_sets[0]),len(best_sets[1]))\n",
    "        true_branch = buildtree(best_sets[0], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        false_branch = buildtree(best_sets[1], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        return DecisionNode(col=best_criteria[0], value=best_criteria[1],\n",
    "                            tb=true_branch, fb=false_branch)\n",
    "    else: # Done splitting - summarize class labels in leaf nodes\n",
    "        return DecisionNode(results=count_labels(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tree printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(leaf_labels):\n",
    "    total = 0\n",
    "    result = {}\n",
    "    for label, count in leaf_labels.items():\n",
    "        total += count\n",
    "        result[label] = count\n",
    "\n",
    "    for label, val in result.items():\n",
    "        result[label] = str(int(result[label]/total * 100))+\"%\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, current_branch, attributes=None,  indent='', leaf_funct=prediction):\n",
    "    # Is this a leaf node?\n",
    "    if tree.results != None:\n",
    "        print(indent + current_branch + str(leaf_funct(tree.results)))\n",
    "    else:\n",
    "        # Print the split question\n",
    "        split_col = str(tree.col)\n",
    "        if attributes is not None:\n",
    "            split_col = attributes[tree.col]\n",
    "        split_val = str(tree.value)\n",
    "        if type(tree.value) == int or type(tree.value) == float:\n",
    "            split_val = \">=\" + str(tree.value)\n",
    "        print(indent + current_branch + split_col + ': ' + split_val + '? ')\n",
    "\n",
    "        # Print the branches\n",
    "        indent = indent + '  '\n",
    "        print_tree(tree.tb, 'T->', attributes, indent)\n",
    "        print_tree(tree.fb, 'F->', attributes, indent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(v, int) or isinstance(v, float):\n",
    "            if v >= tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        else:\n",
    "            if v == tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        return classify(observation, branch)\n",
    "\n",
    "\n",
    "# Classify an observation with missing data\n",
    "def mdclassify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        if v == None:\n",
    "            tr, fr = mdclassify(observation, tree.tb), mdclassify(observation, tree.fb)\n",
    "            tcount = sum(tr.values())\n",
    "            fcount = sum(fr.values())\n",
    "            tw = float(tcount) / (tcount + fcount)\n",
    "            fw = float(fcount) / (tcount + fcount)\n",
    "            result = {}\n",
    "            for k, v in tr.items(): result[k] = v * tw\n",
    "            for k, v in fr.items(): result[k] = v * fw\n",
    "            return result\n",
    "        else:\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            else:\n",
    "                if v == tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            return mdclassify(observation, branch)\n",
    "\n",
    "def max_depth(tree):\n",
    "    if tree.results != None:\n",
    "        return 0\n",
    "    else:\n",
    "        # Compute the depth of each subtree\n",
    "        tDepth = max_depth(tree.tb)\n",
    "        fDepth = max_depth(tree.fb)\n",
    "\n",
    "        # Use the larger one\n",
    "        if (tDepth > fDepth):\n",
    "            return tDepth + 1\n",
    "        else:\n",
    "            return fDepth + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset to numeric\n",
    "\n",
    "The dataset for this lab contains about 450 anonymized student evaluations collected at the University of Texas at Austin, and used in the following publication: __\"Beauty in the Classroom: Instructors' Pulchritude and Putative Pedagogical Productivity\"__. You can learn how the data was collected and the meaning of various data attributes following this [link](https://chance.amstat.org/2013/04/looking-good/).\n",
    "\n",
    "We use a subset of attributes: 'rank', 'ethnicity', 'gender', 'language', 'age', 'class_size', 'class_level',  'avg_beauty_score',  and 'professor_evaluation_score' and try to predict course evaluation score. \n",
    "\n",
    "This smaller dataset can be downloaded from [here](https://drive.google.com/file/d/18wV59AYCVCqL1BIDBYLpL73emp7h8d0T/view?usp=sharing). Download the dataset into your data directory, and update the path to your file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../StudentEvaluations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the dataset into a data frame _df_. First, we will make all attributes numeric, and then we will convert all attributes to categorical labels. The _df_ points to the original dataset. We are going to create two copies: _df_num_ and _df_cat_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "5       tenured  not minority    male  english   59            40     upper   \n",
      "6       tenured  not minority    male  english   59            44     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n",
      "5      3.0        4.3          4.0  \n",
      "6      3.0        2.8          2.1  \n"
     ]
    }
   ],
   "source": [
    "print(df[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that not all attributes are numeric. Let's make them all numeric by using the pandas _replace_ method (see [this post](https://www.geeksforgeeks.org/how-to-convert-categorical-variable-to-numeric-in-pandas/)), which replaces the original values with the predefined set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a copy of the original data frame\n",
    "df_num = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace 'rank', 'ethnicity', 'gender', 'language', and 'cls_level' columns.\n",
    "Let's find out what are the values in each column - to know what to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tenure track', 'tenured', 'teaching'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank\n",
    "df_num['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minority', 'not minority'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ethnicity\n",
    "df_num['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender\n",
    "df_num['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', 'non-english'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language\n",
    "df_num['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['upper', 'lower'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class level\n",
    "df_num['cls_level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a numeric code to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num['rank'].replace(['tenure track', 'tenured', 'teaching'], [1, 2, 3], inplace=True)\n",
    "df_num['ethnicity'].replace(['minority', 'not minority'], [1, 0], inplace=True)\n",
    "df_num['gender'].replace(['female', 'male'], [1, 2], inplace=True)\n",
    "df_num['language'].replace(['english', 'non-english'], [1, 0], inplace=True)\n",
    "df_num['cls_level'].replace(['upper', 'lower'], [2,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the class label an integer by rounding course evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num['course_eval'] = df_num['course_eval'].round(0).astype(int)\n",
    "\n",
    "df_num['course_eval'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check what it looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>language</th>\n",
       "      <th>age</th>\n",
       "      <th>cls_students</th>\n",
       "      <th>cls_level</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>prof_eval</th>\n",
       "      <th>course_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  ethnicity  gender  language  age  cls_students  cls_level  bty_avg  \\\n",
       "0     1          1       1         1   36            43          2      5.0   \n",
       "1     1          1       1         1   36           125          2      5.0   \n",
       "2     1          1       1         1   36           125          2      5.0   \n",
       "3     1          1       1         1   36           123          2      5.0   \n",
       "4     2          0       2         1   59            20          2      3.0   \n",
       "5     2          0       2         1   59            40          2      3.0   \n",
       "6     2          0       2         1   59            44          2      3.0   \n",
       "\n",
       "   prof_eval  course_eval  \n",
       "0        4.7            4  \n",
       "1        4.1            4  \n",
       "2        3.9            4  \n",
       "3        4.8            4  \n",
       "4        4.6            4  \n",
       "5        4.3            4  \n",
       "6        2.8            2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore if there is any correlation between course score and any other attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f485b7329d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "corr = df_num.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree: numeric dataset\n",
    "### 3.1. Using our custom CART algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_num.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_num.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a regression tree, as we are trying to predict a numeric score. We have to use __variance__ as a measure of node purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=variance, min_improvement=0, min_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: >=3.8? \n",
      "  T->prof_eval: >=4.8? \n",
      "    T->cls_students: >=39.0? \n",
      "      T->rank: >=2.0? \n",
      "        T->age: >=62.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_students: >=68.0? \n",
      "            T->cls_students: >=537.0? \n",
      "              T->cls_students: >=581.0? \n",
      "                T->{5.0: '100%'}\n",
      "                F->cls_students: >=574.0? \n",
      "                  T->cls_students: >=579.0? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "            F->rank: >=3.0? \n",
      "              T->{5.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "        F->{4.0: '100%'}\n",
      "      F->age: >=60.0? \n",
      "        T->age: >=64.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_students: >=34.0? \n",
      "            T->{5.0: '100%'}\n",
      "            F->{4.0: '100%'}\n",
      "        F->gender: >=2.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_level: >=2.0? \n",
      "            T->rank: >=2.0? \n",
      "              T->cls_students: >=25.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "              F->cls_students: >=14.0? \n",
      "                T->cls_students: >=26.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "            F->{5.0: '100%'}\n",
      "    F->prof_eval: >=4.6? \n",
      "      T->cls_students: >=27.0? \n",
      "        T->prof_eval: >=4.7? \n",
      "          T->cls_students: >=38.0? \n",
      "            T->cls_level: >=2.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->age: >=60.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "            F->rank: >=3.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "        F->cls_students: >=19.0? \n",
      "          T->age: >=39.0? \n",
      "            T->age: >=59.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "            F->{4.0: '100%'}\n",
      "          F->rank: >=2.0? \n",
      "            T->bty_avg: >=3.667? \n",
      "              T->prof_eval: >=4.7? \n",
      "                T->{4.0: '100%'}\n",
      "                F->cls_students: >=17.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->gender: >=2.0? \n",
      "                    T->cls_students: >=14.0? \n",
      "                      T->{4.0: '100%'}\n",
      "                      F->{5.0: '100%'}\n",
      "                    F->{4.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "            F->prof_eval: >=4.7? \n",
      "              T->{5.0: '100%'}\n",
      "              F->gender: >=2.0? \n",
      "                T->cls_students: >=14.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "      F->age: >=73.0? \n",
      "        T->cls_students: >=17.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "        F->prof_eval: >=3.9? \n",
      "          T->language: >=1.0? \n",
      "            T->cls_students: >=15.0? \n",
      "              T->age: >=33.0? \n",
      "                T->bty_avg: >=6.332999999999999? \n",
      "                  T->bty_avg: >=6.5? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->cls_students: >=78.0? \n",
      "                      T->{4.0: '100%'}\n",
      "                      F->{5.0: '100%'}\n",
      "                  F->prof_eval: >=4.0? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->bty_avg: >=4.833? \n",
      "                      T->cls_students: >=62.0? \n",
      "                        T->{4.0: '100%'}\n",
      "                        F->{3.0: '100%'}\n",
      "                      F->{4.0: '100%'}\n",
      "                F->cls_students: >=22.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->{3.0: '100%'}\n",
      "              F->age: >=43.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->prof_eval: >=4.4? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "            F->cls_students: >=66.0? \n",
      "              T->{3.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "          F->cls_students: >=11.0? \n",
      "            T->bty_avg: >=2.333? \n",
      "              T->ethnicity: >=1.0? \n",
      "                T->age: >=52.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->cls_students: >=16.0? \n",
      "                    T->{3.0: '100%'}\n",
      "                    F->{4.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "  F->prof_eval: >=3.5? \n",
      "    T->age: >=50.0? \n",
      "      T->age: >=70.0? \n",
      "        T->{3.0: '100%'}\n",
      "        F->cls_students: >=122.0? \n",
      "          T->cls_students: >=184.0? \n",
      "            T->{4.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "          F->cls_students: >=47.0? \n",
      "            T->{4.0: '100%'}\n",
      "            F->age: >=58.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->cls_students: >=18.0? \n",
      "                T->ethnicity: >=1.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->rank: >=3.0? \n",
      "                    T->cls_students: >=21.0? \n",
      "                      T->cls_students: >=22.0? \n",
      "                        T->cls_students: >=36.0? \n",
      "                          T->{4.0: '100%'}\n",
      "                          F->age: >=57.0? \n",
      "                            T->cls_students: >=28.0? \n",
      "                              T->{3.0: '100%'}\n",
      "                              F->{4.0: '100%'}\n",
      "                            F->{3.0: '100%'}\n",
      "                        F->{4.0: '100%'}\n",
      "                      F->{3.0: '100%'}\n",
      "                    F->{3.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "      F->bty_avg: >=7.0? \n",
      "        T->{4.0: '100%'}\n",
      "        F->cls_students: >=103.0? \n",
      "          T->{4.0: '100%'}\n",
      "          F->rank: >=3.0? \n",
      "            T->gender: >=2.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "            F->age: >=49.0? \n",
      "              T->cls_students: >=29.0? \n",
      "                T->{3.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "    F->prof_eval: >=2.7? \n",
      "      T->cls_students: >=22.0? \n",
      "        T->prof_eval: >=2.9? \n",
      "          T->{3.0: '100%'}\n",
      "          F->cls_level: >=2.0? \n",
      "            T->age: >=64.0? \n",
      "              T->{3.0: '100%'}\n",
      "              F->{2.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "        F->cls_level: >=2.0? \n",
      "          T->age: >=47.0? \n",
      "            T->{3.0: '100%'}\n",
      "            F->age: >=37.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "      F->gender: >=2.0? \n",
      "        T->cls_students: >=32.0? \n",
      "          T->{2.0: '100%'}\n",
      "          F->{3.0: '100%'}\n",
      "        F->{2.0: '100%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Using sklearn library\n",
    "The decision tree algorithm in sklearn library is not implemented very well. It requires all the attributes to be numeric - while decision trees work best with the categorical attributes. Nevertheless, we will try to run it and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class label has to be binary. So we are going to replace the 'course_eval' column with 3 bins, corresponding to the score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide dataset into features and class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval'],\n",
      "      dtype='object')\n",
      "Index(['course_eval'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = df_num.loc[:, df_num.columns != 'course_eval']\n",
    "print(X.columns)\n",
    "\n",
    "Y = df_num.loc[:, df_num.columns == 'course_eval']\n",
    "print(Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset intro training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different parameters can be specified to build the model:\n",
    "\n",
    "`model = tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', \n",
    "        max_depth=None, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1, \n",
    "        max_features=None, \n",
    "        random_state=None, \n",
    "        min_density=None, \n",
    "        compute_importances=None, \n",
    "        max_leaf_nodes=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 7)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- prof_eval <= 3.75\n",
      "|   |--- prof_eval <= 3.45\n",
      "|   |   |--- prof_eval <= 2.60\n",
      "|   |   |   |--- class: 2\n",
      "|   |   |--- prof_eval >  2.60\n",
      "|   |   |   |--- bty_avg <= 5.83\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |   |   |--- bty_avg >  5.83\n",
      "|   |   |   |   |--- cls_students <= 22.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- cls_students >  22.50\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |--- prof_eval >  3.45\n",
      "|   |   |--- age <= 48.00\n",
      "|   |   |   |--- cls_students <= 93.50\n",
      "|   |   |   |   |--- bty_avg <= 7.25\n",
      "|   |   |   |   |   |--- rank <= 2.50\n",
      "|   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- rank >  2.50\n",
      "|   |   |   |   |   |   |--- bty_avg <= 3.42\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- bty_avg >  3.42\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- bty_avg >  7.25\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- cls_students >  93.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- age >  48.00\n",
      "|   |   |   |--- cls_students <= 110.00\n",
      "|   |   |   |   |--- age <= 57.50\n",
      "|   |   |   |   |   |--- cls_students <= 46.50\n",
      "|   |   |   |   |   |   |--- language <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- language >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- cls_students >  46.50\n",
      "|   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- age >  57.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- cls_students >  110.00\n",
      "|   |   |   |   |--- prof_eval <= 3.65\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- prof_eval >  3.65\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|--- prof_eval >  3.75\n",
      "|   |--- prof_eval <= 4.55\n",
      "|   |   |--- cls_students <= 20.50\n",
      "|   |   |   |--- prof_eval <= 4.25\n",
      "|   |   |   |   |--- cls_students <= 10.50\n",
      "|   |   |   |   |   |--- age <= 55.00\n",
      "|   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- age >  55.00\n",
      "|   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- cls_students >  10.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.25\n",
      "|   |   |   |   |--- age <= 68.00\n",
      "|   |   |   |   |   |--- age <= 42.50\n",
      "|   |   |   |   |   |   |--- gender <= 1.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- gender >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- age >  42.50\n",
      "|   |   |   |   |   |   |--- cls_students <= 19.00\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- cls_students >  19.00\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- age >  68.00\n",
      "|   |   |   |   |   |--- class: 5\n",
      "|   |   |--- cls_students >  20.50\n",
      "|   |   |   |--- rank <= 1.50\n",
      "|   |   |   |   |--- cls_students <= 82.50\n",
      "|   |   |   |   |   |--- cls_students <= 55.00\n",
      "|   |   |   |   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- age >  32.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- cls_students >  55.00\n",
      "|   |   |   |   |   |   |--- ethnicity <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- ethnicity >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- cls_students >  82.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- rank >  1.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |--- prof_eval >  4.55\n",
      "|   |   |--- cls_students <= 36.50\n",
      "|   |   |   |--- age <= 60.50\n",
      "|   |   |   |   |--- ethnicity <= 0.50\n",
      "|   |   |   |   |   |--- prof_eval <= 4.65\n",
      "|   |   |   |   |   |   |--- rank <= 2.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- rank >  2.50\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- prof_eval >  4.65\n",
      "|   |   |   |   |   |   |--- bty_avg <= 3.58\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- bty_avg >  3.58\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- ethnicity >  0.50\n",
      "|   |   |   |   |   |--- class: 5\n",
      "|   |   |   |--- age >  60.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- cls_students >  36.50\n",
      "|   |   |   |--- prof_eval <= 4.75\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.75\n",
      "|   |   |   |   |--- cls_students <= 197.50\n",
      "|   |   |   |   |   |--- rank <= 2.50\n",
      "|   |   |   |   |   |   |--- cls_students <= 73.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- cls_students >  73.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- rank >  2.50\n",
      "|   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- cls_students >  197.50\n",
      "|   |   |   |   |   |--- class: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_list = df_num.columns.to_numpy().tolist()\n",
    "from sklearn.tree import export_text\n",
    "r = export_text(model, feature_names=columns_list[:-1])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Categorical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to replace all the numeric columns in _df_ by categorical labels, using [Pandas _cut_ method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html).\n",
    "\n",
    "First we create a copy of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to bin columns 'age', 'cls_students', 'bty_avg', 'prof_eval', and 'course_eval'. Everything else is already categorical.\n",
    "\n",
    "First thing is to determine the domain for each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 29 to 73\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "age_column = df_cat[\"age\"]\n",
    "print(\"From:\", age_column.min(), \"to\", age_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1.6669999999999998 to 8.167\n"
     ]
    }
   ],
   "source": [
    "# Beauty score\n",
    "bty_ave_column = df_cat[\"bty_avg\"]\n",
    "print(\"From:\", bty_ave_column.min(), \"to\", bty_ave_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 8 to 581\n"
     ]
    }
   ],
   "source": [
    "# Class size\n",
    "num_students_column = df_cat[\"cls_students\"]\n",
    "print(\"From:\", num_students_column.min(), \"to\", num_students_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.3 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Professor score\n",
    "prof_eval_column = df_cat[\"prof_eval\"]\n",
    "print(\"From:\", prof_eval_column.min(), \"to\", prof_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.1 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Course score (class label)\n",
    "course_eval_column = df_cat[\"course_eval\"]\n",
    "print(\"From:\", course_eval_column.min(), \"to\", course_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Age to bins\n",
    "bins = [20, 35, 50, 65, np.inf]\n",
    "names = [ '20-35', '35-50',  '50-65', '65+']\n",
    "\n",
    "df_cat['age'] = pd.cut(df_cat['age'], bins, labels=names)\n",
    "\n",
    "# Class size to bins\n",
    "bins = [0, 15, 30, 50, 100, np.inf]\n",
    "names = [ '<15', '15-30',  '30-50', '50-100', '100+']\n",
    "\n",
    "df_cat['cls_students'] = pd.cut(df_cat['cls_students'], bins, labels=names)\n",
    "\n",
    "# Beauty average to bins\n",
    "bins = [0, 3, 6, 9, np.inf]\n",
    "names = [ '<3', '3-6',  '6-9', '9+']\n",
    "\n",
    "df_cat['bty_avg'] = pd.cut(df_cat['bty_avg'], bins, labels=names)\n",
    "\n",
    "# Professor score to bins\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ '<2', '2-3',  '3-4', '4-4.5', '4.5+']\n",
    "\n",
    "df_cat['prof_eval'] = pd.cut(df_cat['prof_eval'], bins, labels=names)\n",
    "\n",
    "# Course score to class label\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ 'bad', 'fair',  'average', 'good', 'excellent']\n",
    "\n",
    "df_cat['course_eval'] = pd.cut(df_cat['course_eval'], bins, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language    age cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english  35-50        30-50     upper   \n",
      "1  tenure track      minority  female  english  35-50         100+     upper   \n",
      "2  tenure track      minority  female  english  35-50         100+     upper   \n",
      "3  tenure track      minority  female  english  35-50         100+     upper   \n",
      "4       tenured  not minority    male  english  50-65        15-30     upper   \n",
      "\n",
      "  bty_avg prof_eval course_eval  \n",
      "0     3-6      4.5+        good  \n",
      "1     3-6     4-4.5     average  \n",
      "2     3-6       3-4     average  \n",
      "3     3-6      4.5+        good  \n",
      "4      <3      4.5+        good  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree: categorical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_cat.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_cat.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a decision tree (classification), we use entropy as a measure of leaf purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=entropy, min_improvement=0, min_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: 4.5+? \n",
      "  T->cls_students: 15-30? \n",
      "    T->bty_avg: <3? \n",
      "      T->{'good': '100%'}\n",
      "      F->cls_level: upper? \n",
      "        T->bty_avg: 3-6? \n",
      "          T->ethnicity: not minority? \n",
      "            T->{'excellent': '50%', 'good': '50%'}\n",
      "            F->{'excellent': '100%'}\n",
      "          F->{'excellent': '100%'}\n",
      "        F->ethnicity: not minority? \n",
      "          T->rank: tenured? \n",
      "            T->gender: male? \n",
      "              T->age: 50-65? \n",
      "                T->{'good': '100%'}\n",
      "                F->{'excellent': '100%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->gender: female? \n",
      "              T->bty_avg: 6-9? \n",
      "                T->{'good': '50%', 'excellent': '50%'}\n",
      "                F->{'excellent': '100%'}\n",
      "              F->{'excellent': '100%'}\n",
      "          F->{'excellent': '100%'}\n",
      "    F->cls_students: <15? \n",
      "      T->rank: tenured? \n",
      "        T->gender: male? \n",
      "          T->bty_avg: <3? \n",
      "            T->age: 50-65? \n",
      "              T->cls_level: upper? \n",
      "                T->{'good': '66%', 'excellent': '33%'}\n",
      "                F->{'excellent': '100%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->cls_level: upper? \n",
      "              T->{'excellent': '50%', 'good': '50%'}\n",
      "              F->{'good': '100%'}\n",
      "          F->{'excellent': '100%'}\n",
      "        F->gender: male? \n",
      "          T->rank: tenure track? \n",
      "            T->cls_level: upper? \n",
      "              T->{'excellent': '100%'}\n",
      "              F->{'good': '50%', 'excellent': '50%'}\n",
      "            F->{'excellent': '100%'}\n",
      "          F->rank: tenure track? \n",
      "            T->{'excellent': '60%', 'good': '40%'}\n",
      "            F->{'good': '100%'}\n",
      "      F->age: 50-65? \n",
      "        T->cls_students: 100+? \n",
      "          T->cls_level: upper? \n",
      "            T->{'good': '50%', 'excellent': '50%'}\n",
      "            F->{'excellent': '60%', 'good': '40%'}\n",
      "          F->cls_students: 30-50? \n",
      "            T->rank: teaching? \n",
      "              T->{'excellent': '100%'}\n",
      "              F->cls_level: upper? \n",
      "                T->bty_avg: 3-6? \n",
      "                  T->{'excellent': '33%', 'good': '66%'}\n",
      "                  F->{'good': '100%'}\n",
      "                F->{'good': '100%'}\n",
      "            F->{'good': '100%'}\n",
      "        F->cls_students: 100+? \n",
      "          T->{'good': '100%'}\n",
      "          F->age: 65+? \n",
      "            T->{'average': '100%'}\n",
      "            F->cls_level: upper? \n",
      "              T->cls_students: 30-50? \n",
      "                T->gender: male? \n",
      "                  T->rank: tenure track? \n",
      "                    T->{'excellent': '100%'}\n",
      "                    F->{'good': '100%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->rank: tenure track? \n",
      "                      T->ethnicity: minority? \n",
      "                        T->{'good': '100%'}\n",
      "                        F->{'excellent': '33%', 'good': '66%'}\n",
      "                      F->{'good': '33%', 'average': '33%', 'excellent': '33%'}\n",
      "                    F->{'good': '75%', 'average': '25%'}\n",
      "                F->rank: tenure track? \n",
      "                  T->{'good': '100%'}\n",
      "                  F->{'good': '60%', 'excellent': '40%'}\n",
      "              F->{'excellent': '100%'}\n",
      "  F->prof_eval: 4-4.5? \n",
      "    T->cls_students: <15? \n",
      "      T->rank: tenured? \n",
      "        T->age: 65+? \n",
      "          T->{'good': '100%'}\n",
      "          F->cls_level: upper? \n",
      "            T->bty_avg: 3-6? \n",
      "              T->{'good': '100%'}\n",
      "              F->age: 50-65? \n",
      "                T->{'good': '80%', 'average': '20%'}\n",
      "                F->{'average': '100%'}\n",
      "            F->bty_avg: 3-6? \n",
      "              T->age: 50-65? \n",
      "                T->{'average': '100%'}\n",
      "                F->gender: female? \n",
      "                  T->{'average': '50%', 'good': '50%'}\n",
      "                  F->{'good': '100%'}\n",
      "              F->{'good': '100%'}\n",
      "        F->gender: male? \n",
      "          T->rank: tenure track? \n",
      "            T->cls_level: upper? \n",
      "              T->{'excellent': '66%', 'good': '33%'}\n",
      "              F->{'good': '100%'}\n",
      "            F->{'good': '100%'}\n",
      "          F->{'good': '100%'}\n",
      "      F->age: 65+? \n",
      "        T->cls_students: 15-30? \n",
      "          T->{'excellent': '100%'}\n",
      "          F->{'average': '100%'}\n",
      "        F->age: 50-65? \n",
      "          T->bty_avg: 6-9? \n",
      "            T->ethnicity: minority? \n",
      "              T->{'average': '50%', 'good': '50%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->ethnicity: minority? \n",
      "              T->{'average': '100%'}\n",
      "              F->cls_students: 15-30? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'good': '50%', 'average': '50%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->{'good': '100%'}\n",
      "                    F->cls_level: upper? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->{'good': '100%'}\n",
      "                F->cls_level: upper? \n",
      "                  T->cls_students: 30-50? \n",
      "                    T->rank: teaching? \n",
      "                      T->gender: male? \n",
      "                        T->{'average': '100%'}\n",
      "                        F->bty_avg: 3-6? \n",
      "                          T->{'average': '50%', 'good': '50%'}\n",
      "                          F->{'average': '33%', 'good': '66%'}\n",
      "                      F->bty_avg: 3-6? \n",
      "                        T->{'good': '80%', 'average': '20%'}\n",
      "                        F->{'average': '50%', 'good': '50%'}\n",
      "                    F->rank: teaching? \n",
      "                      T->{'good': '100%'}\n",
      "                      F->cls_students: 50-100? \n",
      "                        T->{'average': '37%', 'good': '62%'}\n",
      "                        F->{'good': '71%', 'average': '28%'}\n",
      "                  F->{'average': '100%'}\n",
      "          F->gender: male? \n",
      "            T->rank: tenure track? \n",
      "              T->cls_students: 15-30? \n",
      "                T->age: 35-50? \n",
      "                  T->{'good': '100%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->ethnicity: minority? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->{'good': '100%'}\n",
      "                    F->{'average': '100%'}\n",
      "                F->{'good': '100%'}\n",
      "              F->ethnicity: minority? \n",
      "                T->{'good': '100%'}\n",
      "                F->age: 35-50? \n",
      "                  T->cls_students: 15-30? \n",
      "                    T->cls_level: upper? \n",
      "                      T->bty_avg: 3-6? \n",
      "                        T->rank: teaching? \n",
      "                          T->{'average': '40%', 'good': '60%'}\n",
      "                          F->{'average': '33%', 'good': '66%'}\n",
      "                        F->{'good': '100%'}\n",
      "                      F->{'average': '100%'}\n",
      "                    F->language: english? \n",
      "                      T->rank: teaching? \n",
      "                        T->cls_students: 100+? \n",
      "                          T->{'average': '25%', 'good': '75%'}\n",
      "                          F->{'average': '100%'}\n",
      "                        F->cls_students: 100+? \n",
      "                          T->{'average': '100%'}\n",
      "                          F->bty_avg: 3-6? \n",
      "                            T->cls_students: 30-50? \n",
      "                              T->{'average': '66%', 'good': '33%'}\n",
      "                              F->cls_level: upper? \n",
      "                                T->{'average': '100%'}\n",
      "                                F->{'average': '66%', 'good': '33%'}\n",
      "                            F->{'average': '100%'}\n",
      "                      F->{'good': '100%'}\n",
      "                  F->{'good': '100%'}\n",
      "            F->cls_level: upper? \n",
      "              T->rank: tenured? \n",
      "                T->bty_avg: 3-6? \n",
      "                  T->{'good': '50%', 'average': '50%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->bty_avg: 6-9? \n",
      "                  T->cls_students: 50-100? \n",
      "                    T->{'good': '100%'}\n",
      "                    F->{'average': '100%'}\n",
      "                  F->cls_students: 30-50? \n",
      "                    T->bty_avg: 3-6? \n",
      "                      T->{'average': '83%', 'good': '16%'}\n",
      "                      F->{'average': '100%'}\n",
      "                    F->{'average': '100%'}\n",
      "              F->cls_students: 15-30? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'average': '66%', 'good': '33%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->age: 20-35? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->rank: teaching? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->cls_students: 50-100? \n",
      "                        T->{'average': '100%'}\n",
      "                        F->{'good': '100%'}\n",
      "                    F->{'good': '100%'}\n",
      "    F->prof_eval: 3-4? \n",
      "      T->ethnicity: minority? \n",
      "        T->cls_students: 30-50? \n",
      "          T->rank: tenure track? \n",
      "            T->{'fair': '100%'}\n",
      "            F->{'average': '100%'}\n",
      "          F->bty_avg: 6-9? \n",
      "            T->age: 35-50? \n",
      "              T->cls_students: 15-30? \n",
      "                T->{'good': '100%'}\n",
      "                F->{'average': '100%'}\n",
      "              F->{'average': '100%'}\n",
      "            F->{'average': '100%'}\n",
      "        F->cls_students: <15? \n",
      "          T->rank: teaching? \n",
      "            T->{'average': '100%'}\n",
      "            F->age: 50-65? \n",
      "              T->gender: male? \n",
      "                T->cls_level: upper? \n",
      "                  T->{'average': '66%', 'fair': '33%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->{'average': '100%'}\n",
      "              F->bty_avg: <3? \n",
      "                T->{'fair': '100%'}\n",
      "                F->rank: tenure track? \n",
      "                  T->{'fair': '50%', 'average': '50%'}\n",
      "                  F->{'average': '100%'}\n",
      "          F->rank: tenured? \n",
      "            T->bty_avg: 3-6? \n",
      "              T->{'average': '100%'}\n",
      "              F->cls_students: 15-30? \n",
      "                T->{'average': '100%'}\n",
      "                F->age: 50-65? \n",
      "                  T->cls_students: 30-50? \n",
      "                    T->{'average': '100%'}\n",
      "                    F->cls_level: upper? \n",
      "                      T->gender: female? \n",
      "                        T->{'average': '75%', 'fair': '25%'}\n",
      "                        F->{'average': '100%'}\n",
      "                      F->cls_students: 100+? \n",
      "                        T->{'average': '75%', 'fair': '25%'}\n",
      "                        F->{'fair': '50%', 'average': '50%'}\n",
      "                  F->{'average': '100%'}\n",
      "            F->bty_avg: <3? \n",
      "              T->{'average': '100%'}\n",
      "              F->language: non-english? \n",
      "                T->{'average': '100%'}\n",
      "                F->cls_students: 100+? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->cls_students: 30-50? \n",
      "                    T->cls_level: upper? \n",
      "                      T->age: 50-65? \n",
      "                        T->gender: male? \n",
      "                          T->{'fair': '100%'}\n",
      "                          F->{'average': '100%'}\n",
      "                        F->{'average': '100%'}\n",
      "                      F->{'fair': '100%'}\n",
      "                    F->bty_avg: 3-6? \n",
      "                      T->gender: male? \n",
      "                        T->{'average': '100%'}\n",
      "                        F->age: 50-65? \n",
      "                          T->{'average': '83%', 'fair': '16%'}\n",
      "                          F->cls_students: 15-30? \n",
      "                            T->rank: tenure track? \n",
      "                              T->{'fair': '50%', 'average': '50%'}\n",
      "                              F->{'average': '66%', 'fair': '33%'}\n",
      "                            F->{'average': '100%'}\n",
      "                      F->{'average': '100%'}\n",
      "      F->ethnicity: minority? \n",
      "        T->rank: tenure track? \n",
      "          T->{'fair': '66%', 'average': '33%'}\n",
      "          F->{'fair': '100%'}\n",
      "        F->{'fair': '100%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best we could do for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [TASK 1] Using learned tree for classification\n",
    "\n",
    "Recall at least 3 different courses you have taken, and record the values of the attributes, and the course score that you have given to the course. Run the predict function to see if the decision tree correctly predicts your score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'excellent': '50%', 'good': '50%'}\n",
      "{'fair': '100%'}\n",
      "{'good': '60%', 'excellent': '40%'}\n"
     ]
    }
   ],
   "source": [
    "a =['tenure', 'not minority', 'female','english', '50-65', '15-30', 'upper', '3-6', '4.5+']\n",
    "b =['tenure', 'not minority', 'male','english', '35-50', '15-30', 'upper', '3-6', '<2']\n",
    "c = ['tenure', 'not minority', 'male','english', '35-50', '30- 50', 'upper', '3-6', '4.5+']\n",
    "print(classify(a,tree))\n",
    "print(classify(b,tree))\n",
    "print(classify(c,tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decition tree was kind of right on 2/3 accounts. It was 50% correct with (a) which had a class evaluation of 'excellent'. It was wrong with (b) which actually had an class evaluation of 'poor'. And it was 60% right with (c) which had a class evaluation of 'great'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [TASK 2] Important factors\n",
    "What are the most important attributes in separating good course evaluations from the bad ones? Support your answer by analyzing the tree levels and the leaf outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important attribute is prof-eval as its the first atribute used to split (if its greater then 4.5), and then if thats false we split on prof-eval again (if its between 4 and 4.5), and if thats false we split on it once again, (if its between 3 and 4). SO clearly it is the most important attribute. The second most important is class size. It is used for the second and third split given prof_eval = 4.5+, the second and fourth split given prof_eval = 4-4.5, and the third split given prof_eval = 3-4. So it is a very important factor. The third most inportant is not entirlly clear but I think it is rank. This is becasue if the prof_eval is 4.5+ and class size is not 15-30 and not <15 the we use rank to split next. we also use it if the prof_eval is 4-4.5 and the class size is <15. So it seems to be the most frequant attribute used in high splits after prof_eval and class size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [TASK 3] Rules\n",
    "Extract from the tree at least 3 rules that you find most reliable. Did any of these rules surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) If(prof_eval = 4.5+ and cls_students = 15-30 and bty_avg = < 3)then class_eval = good.<br>\n",
    "2) If(prof_eval = 4-4.5 and cls_students = < 15 and rank = tenured and age = 65+) then class_eval = good. <br>\n",
    "3) If(prof_eval = 3-4 and ethnicity = minority and cls_students = 30-50 and rank = tenure track)then class_eval = fair<br>\n",
    "\n",
    "The first one was kind of intersting as it seems like for a higher beauty score (3-6) there was more chance of getting an exelent review instead of just good. But besides for that these rules are a little too complicated to get meaningful information out of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [BONUS] Web visualization\n",
    "The visualizations of the tree can be made much more expressive with the _d3.js_ visualization library. Sample  _public_html_ folder containing all the required html, css, and javascript files, including the library itself, is provided. \n",
    "\n",
    "In order to create this visualization, all you need is a json file which represents the nodes of the final decision tree. Learn the required JSON format, and implement this conversion in a separate file __dtree_to_json.py__. Submit your file with the lab. \n",
    "\n",
    "Copy the resulting json file into the data directory in the _public_html_ folder, and update the name of the json file in the JavaScript code on line 39 in _index.html_. \n",
    "\n",
    "Note that Chrome would not allow you to run the visualization locally - so if you want to present it to the world you should use a web server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
